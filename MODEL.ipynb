{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fd861eb",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448c903b",
   "metadata": {},
   "source": [
    "The filtered, calculated and encoded features can now be trained with appropriate models.\n",
    "\n",
    "The following approaches are considered:\n",
    "- Multi classification problem with clustered data\n",
    "- Mutli regression problem with two outputs (longitude/latitude)\n",
    "\n",
    "In terms of the data we have the following approaches:\n",
    "- variable sequence length - can take all points in POLYLINE in consideration, mask sequence if necessary\n",
    "- fixed sequence length - take 10 points from beginning of POLYLINE and 10 points from end of polyline \n",
    "\n",
    "\n",
    "Algorithms:\n",
    "- Long term short term NN (multi-class classification and regression)\n",
    "    - able to handle variable sequence length, therefore the total trip POLYLINE can be used\n",
    "- Random forest(regression and classification) \n",
    "    - can handle outliers well as dataset still contains outliers\n",
    "    - runs efficiently on large data set\n",
    "    \n",
    "Metrics:\n",
    "- Classification of clusters: AUC + Avg distance of last point to cluster center\n",
    "- Regression: MAPE + Avg distance of last point to cluster center\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91cc7b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-17 19:28:44.108636: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-17 19:29:02.388869: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec22db62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Softmax\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81e88351",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import json\n",
    "import preprocessing\n",
    "import dask.array as da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d62cd9d-281c-4429-91ce-6c68d072e619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting fastparquet\n",
      "  Downloading fastparquet-2022.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from fastparquet) (21.3)\n",
      "Collecting cramjam>=2.3\n",
      "  Downloading cramjam-2.6.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.20.3 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from fastparquet) (1.21.6)\n",
      "Collecting pandas>=1.5.0\n",
      "  Downloading pandas-1.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m102.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from fastparquet) (2022.10.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from pandas>=1.5.0->fastparquet) (2022.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from pandas>=1.5.0->fastparquet) (2.8.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from packaging->fastparquet) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas>=1.5.0->fastparquet) (1.16.0)\n",
      "Installing collected packages: cramjam, pandas, fastparquet\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.4.4\n",
      "    Uninstalling pandas-1.4.4:\n",
      "      Successfully uninstalled pandas-1.4.4\n",
      "Successfully installed cramjam-2.6.2 fastparquet-2022.12.0 pandas-1.5.2\n"
     ]
    }
   ],
   "source": [
    "!pip install fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b7f526e-3513-4c65-bb99-7666b35723c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cluster=4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "114e1aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_parquet(f's3://think-tank-casestudy/features_engineered/n_cluster_{n_cluster}/feature_engineered_train.parquet')\n",
    "test_data = pd.read_parquet(f's3://think-tank-casestudy/features_engineered/n_cluster_{n_cluster}/feature_engineered_test.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c3ebe9-34a1-4cd5-9915-feaa7bba93dd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1a) Random Forest - Multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93841203-2714-40fc-8749-294af58efa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6487cf91-3089-42e6-bad1-030f5c472a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = preprocessing.create_fix_length_sequences(train_data, 10)\n",
    "test_data = preprocessing.create_fix_length_sequences(test_data, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5f61f22-6720-4ac6-9624-bf46b7b7baf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_config_1 = ['N_COORDINATE_POINTS','TOTAL_DISTANCE_KM', '2013_10',\n",
    "       '2013_11', '2013_12', '2013_7', '2013_8', '2013_9', '2014_1', '2014_2',\n",
    "       '2014_3', '2014_4', '2014_5', '2014_6', '2014_7', '10.0', '12.0',\n",
    "       '13.0', '14.0', '15.0', '18.0', '20.0', '21.0', '23.0', '25.0', '26.0',\n",
    "       '27.0', '28.0', '33.0', '34.0', '35.0', '36.0', '38.0', '40.0', '42.0',\n",
    "       '52.0', '53.0', '54.0', '56.0', '57.0', '58.0', '6.0', '60.0', '61.0',\n",
    "       '63.0', '7.0', '9.0', 'OTHER', 'Cloudy', 'Foggy', 'Rainy', 'Sunny',\n",
    "       'Windy', 'A', 'B', 'C', '16.0', '2014_10', '2014_11', '2014_12',\n",
    "       '2014_8', '2014_9', '47.0', '49.0']\n",
    "label_config_1 = ['CLUSTER_LABEL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f335c1a8-9e88-41db-afde-08ee5d0c36a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = RandomForestClassifier(n_jobs=-1, random_state=0, n_estimators=200, min_samples_split=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ee78996-2bc1-472f-b6c2-e8f56d938e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_sequence_train = pd.DataFrame(train_data.START_SEQUENCE.tolist()).to_numpy()\n",
    "stop_sequence_train = pd.DataFrame(train_data.STOP_SEQUENCE.tolist()).to_numpy()\n",
    "\n",
    "start_sequence_test = pd.DataFrame(test_data.START_SEQUENCE.tolist()).to_numpy()\n",
    "stop_sequence_test = pd.DataFrame(test_data.STOP_SEQUENCE.tolist()).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13f1d23c-eb6c-4ec2-922e-5f04af5f8a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data[features_config_1].to_numpy()\n",
    "y_train = train_data[label_config_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e953012-b6ec-4b33-aace-39531a90653f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_data[features_config_1].to_numpy()\n",
    "y_test = test_data[label_config_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "661fd6aa-92e9-4101-9bc9-f66ca20035cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate((X_train, start_sequence_train,stop_sequence_train), axis=1).astype(float)\n",
    "X_test = np.concatenate((X_test, start_sequence_test,stop_sequence_test), axis=1).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7abb2fb-df4c-44f6-8a1b-75e557e1d62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7203/2693113725.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  X_train_pred = estimator.fit(X_train,y_train)\n"
     ]
    }
   ],
   "source": [
    "X_train_pred = estimator.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf8e6a8-831c-4268-a6a0-2815bfeebb97",
   "metadata": {
    "tags": []
   },
   "source": [
    "###  2) LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77d78a6-9713-4978-a66f-fd4cbdddfd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill nas with arbitrary large number to mask later\n",
    "df_sequence_train = da.from_array(pd.DataFrame(train_data.SEQUENCE.tolist()).fillna(2000).to_numpy())\n",
    "df_sequence_test = da.from_array(pd.DataFrame(test_data.SEQUENCE.tolist()).fillna(2000).to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8041f019-4c99-4a24-bca9-4280d155ad02",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_config_2 = ['N_COORDINATE_POINTS','TOTAL_DISTANCE_KM','2013_10',\n",
    "       '2013_11', '2013_12', '2013_7', '2013_8', '2013_9', '2014_1', '2014_2',\n",
    "       '2014_3', '2014_4', '2014_5', '2014_6', '2014_7', '10.0', '12.0',\n",
    "       '13.0', '14.0', '15.0', '18.0', '20.0', '21.0', '23.0', '25.0', '26.0',\n",
    "       '27.0', '28.0', '33.0', '34.0', '35.0', '36.0', '38.0', '40.0', '42.0',\n",
    "       '52.0', '53.0', '54.0', '56.0', '57.0', '58.0', '6.0', '60.0', '61.0',\n",
    "       '63.0', '7.0', '9.0', 'OTHER', 'Cloudy', 'Foggy', 'Rainy', 'Sunny',\n",
    "       'Windy', 'A', 'B', 'C', '16.0', '2014_10', '2014_11', '2014_12',\n",
    "       '2014_8', '2014_9', '47.0', '49.0']\n",
    "label_config_2 = ['CLUSTER_LABEL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61eacd8-8e93-4a75-8a9e-6498d2c83f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data[features_config_2].to_numpy().astype(float)\n",
    "X_test = test_data[features_config_2].to_numpy().astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82553ba-48f3-46a7-99f7-4778a87b4295",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate((df_sequence_train, X_train), axis=1)\n",
    "X_test = np.concatenate((df_sequence_test, X_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24874745-e6a0-4e83-a8ad-461afbe78a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data[label_config_2]\n",
    "y_test =  test_data[label_config_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a0ce96-357a-4472-ade7-dfeab32e4023",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(input_shape=(X_train.shape[0], X_train.shape[1])))\n",
    "model.add(tf.keras.layers.Masking(mask_value=2000))\n",
    "model.add(LSTM(32, activation='relu'))\n",
    "model.add(Softmax(4000), activation='linear')\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['AUC'])\n",
    "\n",
    "X_pred_train = model.fit(X_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
