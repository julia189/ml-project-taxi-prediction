{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f83d6a38",
   "metadata": {},
   "source": [
    "### 0.1 Case Study\n",
    "\n",
    "#### Scenario\n",
    "At BMW, we reimagine the future of mobility. Lets fast forward to 2030, and flying taxis are roaming above our cities, bringing people to\n",
    "their desired destination. You work for, Duoro Hawk a company that is pioneering the world's first large fleet of fully electric, self-piloting\n",
    "autonomous flying taxis. The company wants to deploy the first network of autonomous air taxis in the coming year. As part of our data\n",
    "science and enginering team, you are responsible for predicting the destination of our fleet of autonomous flying taxis based on the\n",
    "manned test flights that have been performed.\n",
    "\n",
    "#### About the Dataset\n",
    "A fictional dataset describing a complete year (from 01/07/2014 to 30/06/2014) of all the trajectories for all 442 of our flying taxis that\n",
    "were simulated in the city of Porto. Our autonomous fleet of taxis fly from a central ground station\n",
    "• There are three different types of rides: A) phone call-based, B) stand-based where people wait at a stand for their flying taxi or C) \n",
    "random place. For type A, we provide an anonymized ID, to represent the telephone call. Categories B and C refers to cases where the\n",
    "taxis were directly called by the customer.\n",
    "\n",
    "#### Dataset\n",
    "##### train.csv\n",
    "Each data sample corresponds to one completed trip. It contains a total of 9 (nine) features, described as follows:\n",
    "\n",
    "- TRIP_ID: (String) It contains an unique identifier for each trip;\n",
    "\n",
    "- CALL_TYPE: (char) It identifies the way used to demand this service. It may contain one of three possible values:\n",
    "     - ‘A’ if this trip was dispatched from the central;\n",
    "     - ‘B’ if this trip was demanded directly to a taxi driver on a specific stand;\n",
    "     - ‘C’ otherwise (i.e. a trip demanded on a random street).\n",
    "     \n",
    "- ORIGIN_CALL: (integer) It contains an unique identifier for each phone number which was used to demand, at least, one service. It identifies the trip’s customer if CALLTYPE=’A’. Otherwise, it assumes a NULL value;\n",
    "\n",
    "- ORIGINSTAND: (integer): It contains an unique identifier for the taxi stand. It identifies the starting point of the trip if CALLTYPE=’B’. Otherwise, it assumes a NULL value;\n",
    "\n",
    "- WEATHER: (String): Information on the weather that day, unique values include: Sunny, Rainy, Cloudy, Windy, and Foggy\n",
    "- TAXI_ID: (integer): It contains an unique identifier for the flying taxi that performed each trip;\n",
    "- TIMESTAMP: (integer) Unix Timestamp (in seconds). It identifies the trip’s start;\n",
    "- MISSING_DATA: (Boolean) It is FALSE when the GPS data stream is complete and TRUE whenever one (or more) locations are missing\n",
    "- POLYLINE: (String): It contains a list of GPS coordinates (i.e. WGS84 format) mapped as a string. The beginning and the end of the string are identified with brackets (i.e. [ and ], respectively). Each pair of coordinates is also identified by the same brackets as\n",
    "- [LONGITUDE, LATITUDE]. This list contains one pair of coordinates for each 15 seconds of trip. The last list item corresponds to the trip’s destination while the first one represents its start\n",
    "\n",
    "\n",
    "##### test.csv\n",
    "Personal records for the remaining one-third (~110) of the trips, to be used as test data. Your task is to predict the value of coordinates of the trip‘s destination\n",
    "\n",
    "##### sample_submission.csv \n",
    "A submission file in the correct format.\n",
    "- TripId - Id for each Tip in the test set\n",
    "- Longitude - the longitude of the destination of the flying taxi\n",
    "- Latitude – the latitude of the destination of the flying taxi\n",
    "\n",
    "The total travel time of the trip (the prediction target of this competition) is defined as the (number of points-1) x 15 seconds. For example, a trip with 101 data points in POLYLINE has a length of (101-1) * 15 = 1500 seconds. Some trips have missing data points in POLYLINE, indicated by MISSING_DATA column, and it is part of the challenge how you utilize this knowledge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c11c59d",
   "metadata": {},
   "source": [
    "### 0.2 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "94ce6436-3233-4994-9e06-543f81293c7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: awswrangler in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (3.4.2)\n",
      "Requirement already satisfied: boto3<2.0.0,>=1.20.32 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from awswrangler) (1.28.80)\n",
      "Requirement already satisfied: botocore<2.0.0,>=1.23.32 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from awswrangler) (1.31.80)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from awswrangler) (1.22.4)\n",
      "Requirement already satisfied: packaging<24.0,>=21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from awswrangler) (21.3)\n",
      "Requirement already satisfied: pandas<3.0.0,>=1.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from awswrangler) (2.1.1)\n",
      "Requirement already satisfied: pyarrow>=7.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from awswrangler) (13.0.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from awswrangler) (4.8.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3<2.0.0,>=1.20.32->awswrangler) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.8.0,>=0.7.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3<2.0.0,>=1.20.32->awswrangler) (0.7.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore<2.0.0,>=1.23.32->awswrangler) (2.8.2)\n",
      "Requirement already satisfied: urllib3<2.1,>=1.25.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore<2.0.0,>=1.23.32->awswrangler) (1.26.18)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from packaging<24.0,>=21.1->awswrangler) (3.1.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas<3.0.0,>=1.2.0->awswrangler) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas<3.0.0,>=1.2.0->awswrangler) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<2.0.0,>=1.23.32->awswrangler) (1.16.0)\n",
      "Requirement already satisfied: geojson in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install awswrangler\n",
    "!pip install geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc49bb0d-54f4-4b27-ba92-197b9f9245b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import time\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import awswrangler as aw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e9ca2c20-80e5-417a-898f-f655838fc693",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "utils_path = os.path.join('/home/ec2-user/SageMaker/thinktank_casestudy/src/utils/')\n",
    "pp_path = os.path.join('/home/ec2-user/SageMaker/thinktank_casestudy/src/preprocessing/')\n",
    "\n",
    "sys.path.append(utils_path)\n",
    "sys.path.append(pp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b58a018a-1467-48fa-a9ad-975d7935f9b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from preprocessing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac948fb9",
   "metadata": {},
   "source": [
    "### 0.3 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "34ffaf14-9691-42eb-9fef-da502c836a63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_parquet('s3://think-tank-casestudy/train_df.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "26f244ba-9ede-4e8b-a253-beb8516dc693",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_parquet('s3://think-tank-casestudy/test_df.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a9ede015-69e7-4e7d-89bb-1484e23f8600",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'TRIP_ID', 'CALL_TYPE', 'ORIGIN_CALL', 'ORIGIN_STAND',\n",
       "       'TAXI_ID', 'TIMESTAMP', 'DAY_TYPE', 'MISSING_DATA', 'POLYLINE',\n",
       "       'WEATHER'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9b4e61c9-8377-4c68-a0dc-a3c58d581f38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TRIP_ID', 'CALL_TYPE', 'ORIGIN_CALL', 'ORIGIN_STAND', 'TAXI_ID',\n",
       "       'TIMESTAMP', 'DAY_TYPE', 'MISSING_DATA', 'POLYLINE', 'WEATHER'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d6516f83-d4f7-4f91-8ee9-009040f0040a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>CALL_TYPE</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>DAY_TYPE</th>\n",
       "      <th>MISSING_DATA</th>\n",
       "      <th>POLYLINE</th>\n",
       "      <th>WEATHER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1372636858620000589</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000589</td>\n",
       "      <td>1372636858</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.618643,41.141412],[-8.618499,41.141376],[...</td>\n",
       "      <td>Rainy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1372637303620000596</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20000596</td>\n",
       "      <td>1372637303</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.639847,41.159826],[-8.640351,41.159871],[...</td>\n",
       "      <td>Foggy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1372636951620000320</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000320</td>\n",
       "      <td>1372636951</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.612964,41.140359],[-8.613378,41.14035],[-...</td>\n",
       "      <td>Rainy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1372636854620000520</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000520</td>\n",
       "      <td>1372636854</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.574678,41.151951],[-8.574705,41.151942],[...</td>\n",
       "      <td>Cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1372637091620000337</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000337</td>\n",
       "      <td>1372637091</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.645994,41.18049],[-8.645949,41.180517],[-...</td>\n",
       "      <td>Windy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0              TRIP_ID CALL_TYPE  ORIGIN_CALL  ORIGIN_STAND  \\\n",
       "0           0  1372636858620000589         C          NaN           NaN   \n",
       "1           1  1372637303620000596         B          NaN           7.0   \n",
       "2           2  1372636951620000320         C          NaN           NaN   \n",
       "3           3  1372636854620000520         C          NaN           NaN   \n",
       "4           4  1372637091620000337         C          NaN           NaN   \n",
       "\n",
       "    TAXI_ID   TIMESTAMP DAY_TYPE  MISSING_DATA  \\\n",
       "0  20000589  1372636858        A         False   \n",
       "1  20000596  1372637303        A         False   \n",
       "2  20000320  1372636951        A         False   \n",
       "3  20000520  1372636854        A         False   \n",
       "4  20000337  1372637091        A         False   \n",
       "\n",
       "                                            POLYLINE WEATHER  \n",
       "0  [[-8.618643,41.141412],[-8.618499,41.141376],[...   Rainy  \n",
       "1  [[-8.639847,41.159826],[-8.640351,41.159871],[...   Foggy  \n",
       "2  [[-8.612964,41.140359],[-8.613378,41.14035],[-...   Rainy  \n",
       "3  [[-8.574678,41.151951],[-8.574705,41.151942],[...  Cloudy  \n",
       "4  [[-8.645994,41.18049],[-8.645949,41.180517],[-...   Windy  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6ddc0174-1ddc-49e8-9ba7-3713d168aa31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = train_data.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f3c497",
   "metadata": {},
   "source": [
    "Target prediction is longitude and latitude for each TRIP in test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5d3a7c",
   "metadata": {},
   "source": [
    "DAY_TYPE is not mentioned in list of attributes and attribute is uniformly distributed for both train and test data --> no information gain and can therefore be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "64f4fb91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = train_data.drop(['DAY_TYPE'], axis=1)\n",
    "test_data = test_data.drop(['DAY_TYPE'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2e1ae877-65cf-4ff6-b14e-90b2fd5c0ce1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'convert_polyline_to_geojson_format' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_data \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_polyline_to_geojson_format\u001b[49m(data\u001b[38;5;241m=\u001b[39mtrain_data,\n\u001b[1;32m      2\u001b[0m                                                 name_column\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPOLYLINE\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'convert_polyline_to_geojson_format' is not defined"
     ]
    }
   ],
   "source": [
    "train_data = convert_polyline_to_geojson_format(data=train_data,\n",
    "                                                name_column='POLYLINE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e60bb0f-bd7c-4446-b116-26bd5c73e759",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5dcb7cd3-e31b-4897-9407-672deb5f917b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data = adjust_datatypes(data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf612ce7-3570-4f11-b866-c6bc1221e9cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = adjust_datatypes(data=train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e81075f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(train_data.TIMESTAMP_DT.min())\n",
    "print(train_data.TIMESTAMP_DT.max())\n",
    "print(test_data.TIMESTAMP_DT.min())\n",
    "print(test_data.TIMESTAMP_DT.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5add455",
   "metadata": {},
   "source": [
    "All dates are in previously defined valid ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3dc64f",
   "metadata": {},
   "source": [
    "### 0.4 Sanity Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d68863",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Assert that train and test data have same column shape and attributes\n",
    "def perform_sanity_checks():\n",
    "    try:\n",
    "        assert(train_data.shape[1] == test_data.shape[1])\n",
    "        print(\"Column shape train vs test passed\")\n",
    "        assert((train_data.columns == test_data.columns).all())\n",
    "        print(\"Column naming train vs test passed\")\n",
    "        assert(train_data.TRIP_ID.nunique() == train_data.shape[0])\n",
    "        print(\"Check for unique trips passed - train data\")\n",
    "        assert(test_data.TRIP_ID.nunique() == test_data.shape[0])\n",
    "        print(\"Check for unique trips passed - test data\")\n",
    "        print('All checks passed!')\n",
    "    except:\n",
    "        print(\"Sanity Check failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ef81d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "perform_sanity_checks()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5377f66",
   "metadata": {},
   "source": [
    "### 0.5 Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6ed32b",
   "metadata": {},
   "source": [
    "#### 0.5.1 NAN/Null Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ba67ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5088d90",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98693a1b",
   "metadata": {},
   "source": [
    "ORIGIN_CALL and ORIGIN_STAND have null values which is to be expected as they are determined dependent on the call type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24ae5af",
   "metadata": {},
   "source": [
    "#### 0.5.2 Duplicated TRIP_IDs\n",
    "The Sanity Checks in 0.4 showed that the TRIP_IDs are not unique. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcf96ef-6ae1-42f2-a2cc-b76b464b14be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vc = train_data.TRIP_ID.value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a36dca7-1c99-445e-81df-b9d19f6f56cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e017b87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DUPLICATED_IDs = vc[vc['count'] > 1]['TRIP_ID'].unique()\n",
    "print(f'{len(DUPLICATED_IDs)} TRIP_IDs are duplicated')\n",
    "print(f'{(len(DUPLICATED_IDs)/train_data.TRIP_ID.nunique()*100)} % out of all unique TRIPs.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0bc54e",
   "metadata": {},
   "source": [
    "**Findings**:\n",
    "- 159 cases\n",
    "- Missing Data == False for all cases\n",
    "- 80 TRIP_IDs are duplicated\n",
    "- Affected data is insignifcant (less than 1% of all  TRIPs)\n",
    "\n",
    "**Assumptions**:\n",
    "- Potential reasons could be cancellation by dispatcher after a person called for some reasons, failed flight attempts, broken flight taxi etc.\n",
    "- The trips per ID with the longest POLYLINE are kept as these are assumed to be valid trips. Additionally trips with no POLYLINE or only one coordinate point are assumed invalid and filtered from the dataset. \n",
    "- Also it is assumed that only POLYLINEs with at least 10 coordinate points are sufficient. \n",
    "- Further investigation will should be done and analyzed together with sensor/technical data from flight taxi. Also the reason could be that a flight is interrupted and re-started again, that could be analyzed by plotting the POLYLINE and compare the start and end point of the duplicated TRIPs. Will be part of further optimization\n",
    "\n",
    "To do as mentioned in Assumptions, the number of points in the POLYLINE needs to be calculated. In addition we calculate the total flight time at this point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69791552",
   "metadata": {},
   "source": [
    "#### 0.5.3 Data Cleaning POLYLINE\n",
    "To do cleaning regarding the POLYLINE, a few more attributes are calculated:\n",
    "- N_COORDINATE_POINTS - number of total points\n",
    "- TOTAL_FLIGHT_TIME_SECONDS, TOTAL_FLIGHT_TIME_MINUTES - flight time total\n",
    "- START_POINT - Starting point for each trip\n",
    "- DEST_POINT - Last point for each trip \n",
    "- TOTAL_DISTANCE - total distance of trip in km with haversine formulam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5692cab1-b466-428d-9dae-941e88bba0d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0321d4-41de-4445-8f73-d44b8ba1df94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = calculate_POLYLINE_features(train_data)\n",
    "test_data = calculate_POLYLINE_features(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb45d0c4-06f9-484d-95d1-20e0f829aae0",
   "metadata": {},
   "source": [
    "Based on assumption, keeping only polylines with at least 10 coordinate points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb1209d-11b5-4015-9b6c-dfad8be939c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = filter_invalid_trips(train_data, n_points=10)\n",
    "test_data = filter_invalid_trips(test_data, n_points=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ef2b99-1daa-40de-a7f3-a8d3698a7da3",
   "metadata": {},
   "source": [
    "Calculating the total distance of the trip in km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e3e66b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = calculate_total_distance(train_data)\n",
    "test_data = calculate_total_distance(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1d516f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data['SEQUENCE'] = train_data.POLYLINE.apply(lambda row: np.hstack(row))\n",
    "test_data['SEQUENCE'] = test_data.POLYLINE.apply(lambda row: np.hstack(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34594ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = train_data.drop(['POLYLINE'],axis=1)\n",
    "test_data = test_data.drop(['POLYLINE'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b1825f",
   "metadata": {},
   "source": [
    "#### 0.5.4 MISSING_DATA == TRUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35352209",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f'Train Data: {train_data.MISSING_DATA.value_counts()[1]} Trips with MISSING_DATA == True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b5cbfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data.MISSING_DATA.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779cb316",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data[train_data.MISSING_DATA == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4983008b",
   "metadata": {},
   "source": [
    "- Amount of data with missing values insignificant compared to total amount of data\n",
    "- Majority of trips is WEATHER == Rainy, however total amount of trips is not significant enought to draw a conclusion/make an assumption\n",
    "- Number of points/length of polyline is in general unequal so there is no indication in that sense how much data is missing, also no information if data is missing at the start/middle or end of POLYLINE \n",
    "\n",
    "Based on these Findings, I would simply drop these values, mainly as their effect is expected to be very little. If the number of data samples would be higher, I would try to impute the missing coordinates in this case with the Nearest Neighbour. However the problem of knowing if the cooordinates are missing in start/middle/end would prevail. In case I find very similar trips through additional logic (difference in n_coordinate_points <= 5 and overall_distance between points < threshold) I could minimize this problem. These tasks could be part of further optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ebbd47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = train_data[train_data.MISSING_DATA != True]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf675a9",
   "metadata": {},
   "source": [
    "#### 0.5.5 OUTLIER\n",
    "To handle the outliers, we look at statistical indicators and plot the boxplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d882f1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8828bcee",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "sns.boxplot(data=train_data[['N_COORDINATE_POINTS','TOTAL_FLIGHT_TIME_MINUTES','TOTAL_DISTANCE_KM']])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94ef896",
   "metadata": {},
   "source": [
    "The cotinous attributes show a high number of outliers, with the number of coordinate points the widest spread.\n",
    "To avoid loosing too much data, keeping the 95% quantile of the data regarding the N_COORDINATE_POINTS and TOTAL_DISTANCE seems to be the best choice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edd5d06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = train_data[(train_data.N_COORDINATE_POINTS <= train_data.N_COORDINATE_POINTS.quantile(0.90))\n",
    "                 & (train_data.TOTAL_DISTANCE_KM <= train_data.TOTAL_DISTANCE_KM.quantile(0.90))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a648c307",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "sns.boxplot(data=train_data[['N_COORDINATE_POINTS','TOTAL_FLIGHT_TIME_MINUTES','TOTAL_DISTANCE_KM']])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc39cc8e",
   "metadata": {},
   "source": [
    "We can see some outliers remaining, however the spread is significantly reduced. Outliers in the test data will be kept to avoid too much reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912bb117",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.set()\n",
    "plt.hist(train_data.TOTAL_FLIGHT_TIME_MINUTES, \n",
    "         label=f'Post invalid trips N={train_data.shape[0]}')\n",
    "plt.title('Distribution - total flight time in minutes (95% quantile for visualization reasons)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095ddc23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.set()\n",
    "plt.hist(train_data.TOTAL_DISTANCE_KM, \n",
    "         label=f'Post invalid trips N={train_data.shape[0]}')\n",
    "plt.title('Distribution - Count total distance km')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934840d5",
   "metadata": {},
   "source": [
    "The reduction of the training data does not have a major effect on the data distribution. Optimization could be to compare performance with/without outliers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf36a9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "perform_sanity_checks()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384185cd",
   "metadata": {},
   "source": [
    "#### 0.5.5 CALL_TYPE LOGIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b74a333",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_call_type(data):\n",
    "    data_A = data[(data.CALL_TYPE == 'A') & (data.ORIGIN_CALL == np.NaN)]\n",
    "    data_B = data[(data.CALL_TYPE == 'B') & (data.ORIGIN_STAND == np.NaN)]\n",
    "    data_C = data[(data.CALL_TYPE == 'C') & (data.ORIGIN_STAND != np.NaN)].ORIGIN_STAND.nunique()\n",
    "    return data_A, data_B, data_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2c6a94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "check_call_type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca47ab5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "check_call_type(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c79ef3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data.drop(['TIMESTAMP','MISSING_DATA','TOTAL_FLIGHT_TIME_SECONDS'],\n",
    "                axis=1, inplace=True)\n",
    "test_data.drop(['TIMESTAMP','MISSING_DATA','TOTAL_FLIGHT_TIME_SECONDS'],\n",
    "                axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddcb8c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d298d356",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aw.s3.to_parquet(df=train_data, path='s3://think-tank-casestudy/preprocessed_data/train_data_preprocess.parquet')\n",
    "aw.s3.to_parquet(df=test_data, path='s3://think-tank-casestudy/preprocessed_data/test_data_preprocess.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
