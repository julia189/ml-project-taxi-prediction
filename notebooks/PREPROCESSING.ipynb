{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f83d6a38",
   "metadata": {},
   "source": [
    "### 0.1 Case Study\n",
    "\n",
    "#### Scenario\n",
    "At BMW, we reimagine the future of mobility. Lets fast forward to 2030, and flying taxis are roaming above our cities, bringing people to\n",
    "their desired destination. You work for, Duoro Hawk a company that is pioneering the world's first large fleet of fully electric, self-piloting\n",
    "autonomous flying taxis. The company wants to deploy the first network of autonomous air taxis in the coming year. As part of our data\n",
    "science and enginering team, you are responsible for predicting the destination of our fleet of autonomous flying taxis based on the\n",
    "manned test flights that have been performed.\n",
    "\n",
    "#### About the Dataset\n",
    "A fictional dataset describing a complete year (from 01/07/2014 to 30/06/2014) of all the trajectories for all 442 of our flying taxis that\n",
    "were simulated in the city of Porto. Our autonomous fleet of taxis fly from a central ground station\n",
    "• There are three different types of rides: A) phone call-based, B) stand-based where people wait at a stand for their flying taxi or C) \n",
    "random place. For type A, we provide an anonymized ID, to represent the telephone call. Categories B and C refers to cases where the\n",
    "taxis were directly called by the customer.\n",
    "\n",
    "#### Dataset\n",
    "##### train.csv\n",
    "Each data sample corresponds to one completed trip. It contains a total of 9 (nine) features, described as follows:\n",
    "\n",
    "- TRIP_ID: (String) It contains an unique identifier for each trip;\n",
    "\n",
    "- CALL_TYPE: (char) It identifies the way used to demand this service. It may contain one of three possible values:\n",
    "     - ‘A’ if this trip was dispatched from the central;\n",
    "     - ‘B’ if this trip was demanded directly to a taxi driver on a specific stand;\n",
    "     - ‘C’ otherwise (i.e. a trip demanded on a random street).\n",
    "     \n",
    "- ORIGIN_CALL: (integer) It contains an unique identifier for each phone number which was used to demand, at least, one service. It identifies the trip’s customer if CALLTYPE=’A’. Otherwise, it assumes a NULL value;\n",
    "\n",
    "- ORIGINSTAND: (integer): It contains an unique identifier for the taxi stand. It identifies the starting point of the trip if CALLTYPE=’B’. Otherwise, it assumes a NULL value;\n",
    "\n",
    "- WEATHER: (String): Information on the weather that day, unique values include: Sunny, Rainy, Cloudy, Windy, and Foggy\n",
    "- TAXI_ID: (integer): It contains an unique identifier for the flying taxi that performed each trip;\n",
    "- TIMESTAMP: (integer) Unix Timestamp (in seconds). It identifies the trip’s start;\n",
    "- MISSING_DATA: (Boolean) It is FALSE when the GPS data stream is complete and TRUE whenever one (or more) locations are missing\n",
    "- POLYLINE: (String): It contains a list of GPS coordinates (i.e. WGS84 format) mapped as a string. The beginning and the end of the string are identified with brackets (i.e. [ and ], respectively). Each pair of coordinates is also identified by the same brackets as\n",
    "- [LONGITUDE, LATITUDE]. This list contains one pair of coordinates for each 15 seconds of trip. The last list item corresponds to the trip’s destination while the first one represents its start\n",
    "\n",
    "\n",
    "##### test.csv\n",
    "Personal records for the remaining one-third (~110) of the trips, to be used as test data. Your task is to predict the value of coordinates of the trip‘s destination\n",
    "\n",
    "##### sample_submission.csv \n",
    "A submission file in the correct format.\n",
    "- TripId - Id for each Tip in the test set\n",
    "- Longitude - the longitude of the destination of the flying taxi\n",
    "- Latitude – the latitude of the destination of the flying taxi\n",
    "\n",
    "The total travel time of the trip (the prediction target of this competition) is defined as the (number of points-1) x 15 seconds. For example, a trip with 101 data points in POLYLINE has a length of (101-1) * 15 = 1500 seconds. Some trips have missing data points in POLYLINE, indicated by MISSING_DATA column, and it is part of the challenge how you utilize this knowledge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c11c59d",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc49bb0d-54f4-4b27-ba92-197b9f9245b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import time\n",
    "import json\n",
    "import awswrangler as aw\n",
    "import geojson\n",
    "from shapely import geometry\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55465a0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "is_sagemaker_notebook = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9ca2c20-80e5-417a-898f-f655838fc693",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if is_sagemaker_notebook:\n",
    "    prefix = \"/home/ec2-user/SageMaker\"\n",
    "else:\n",
    "    prefix = \"/Users/Q619505/PycharmProjects\"\n",
    "\n",
    "utils_path = os.path.join(f'{prefix}/ml-project-taxi-prediction/src/utils/')\n",
    "pp_path = os.path.join(f'{prefix}/ml-project-taxi-prediction/src/preprocessing/')\n",
    "\n",
    "if utils_path not in sys.path:\n",
    "    sys.path.append(utils_path)\n",
    "\n",
    "if pp_path not in sys.path:\n",
    "    sys.path.append(pp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b58a018a-1467-48fa-a9ad-975d7935f9b2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from utils import convert_datatypes\n",
    "from geo_spatial import convert_polyline_to_geojson_format, calculate_polyline_features, haversine_distance, calculate_total_distance\n",
    "from data_cleaning import filter_invalid_trips\n",
    "from data_ingestion import athena_query\n",
    "from utils import convert_datatypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac948fb9",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34ffaf14-9691-42eb-9fef-da502c836a63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_parquet('s3://think-tank-casestudy/train_df.parquet')\n",
    "test_data = pd.read_parquet('s3://think-tank-casestudy/test_df.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5f8a89-5dfe-4691-a369-f8de9d455d6e",
   "metadata": {},
   "source": [
    "#### Dropping unuseful columns \n",
    "- **Unnamed: 0** column is default index and not appropriately named\n",
    "- **DAY_TYPE** column is deterministic, therefore will not add any value/information gain to an ML approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ddc0174-1ddc-49e8-9ba7-3713d168aa31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = train_data.drop(['Unnamed: 0'], axis=1)\n",
    "train_data = train_data.drop(['DAY_TYPE'], axis=1)\n",
    "test_data = test_data.drop(['DAY_TYPE'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342974f7-e3f9-4ffd-af71-28a5fa581b98",
   "metadata": {},
   "source": [
    "#### Converting column names\n",
    "Converting columns names to lowercase as more appropriate to formatting standards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83748c04-a4ee-46d7-83dc-e05cbdf0c7a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data.columns = [column_.lower() for column_ in train_data.columns]\n",
    "test_data.columns = [column_.lower() for column_ in test_data.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd3fe78-a061-4723-9529-41faeeb79e4e",
   "metadata": {},
   "source": [
    "#### Converting datatypes \n",
    "- **TRIP_ID** object type in python is appropriate to string\n",
    "- **CALL_TYPE** object type in python is appropriate to char\n",
    "- **ORIGIN_CALL** integer type --> int\n",
    "- **ORIGIN_STAND** object type in python is appropriate to string\n",
    "- **WEATHER** object type in python is appropriate to string\n",
    "- **TAXI_ID** integer type --> int\n",
    "- **TIMESTAMP** Unix Timestamps --> convert to datetime timestamp\n",
    "- **MISSING_DATA** boolean --> bool \n",
    "- **POLYLINE** String --> convert to geojson format for proper future processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1ae877-65cf-4ff6-b14e-90b2fd5c0ce1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = convert_polyline_to_geojson_format(data=train_data, name_column='polyline')\n",
    "test_data = convert_polyline_to_geojson_format(data=test_data, name_column='polyline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561d0880-cc5e-447f-8837-e763124f0fc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns_datatypes_dict = {\n",
    "    'trip_id': 'object',\n",
    "    'call_type': 'object',\n",
    "    'origin_call': 'object',\n",
    "    'origin_stand': 'object',\n",
    "    'taxi_id': 'int',\n",
    "    'timestamp': 'datetime',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf612ce7-3570-4f11-b866-c6bc1221e9cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = convert_datatypes(data=train_data.copy(), columns_datatypes_dict=columns_datatypes_dict)\n",
    "test_data = convert_datatypes(data=test_data.copy(), columns_datatypes_dict=columns_datatypes_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8077d4e7-d965-4022-9418-8b5f854a51c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "All dates are in previously defined valid ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e81075f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(train_data.timestamp.min())\n",
    "print(train_data.timestamp.max())\n",
    "print(test_data.timestamp.min())\n",
    "print(test_data.timestamp.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3dc64f",
   "metadata": {},
   "source": [
    "### Sanity Checks\n",
    "Assert that train and test data have same column shape\n",
    "and that the trip id is in fact unique identifier of the record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d68863",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    assert(train_data.shape[1] == test_data.shape[1])\n",
    "    print(\"Column shape train vs test passed\")\n",
    "    assert((train_data.columns == test_data.columns).all())\n",
    "    print(\"Column naming train vs test passed\")\n",
    "    assert(train_data.trip_id.nunique() == train_data.shape[0])\n",
    "    print(\"Check for unique trips passed - train data\")\n",
    "    assert(test_data.trip_id.nunique() == test_data.shape[0])\n",
    "    print(\"Check for unique trips passed - test data\")\n",
    "    print('All checks passed!')\n",
    "except:\n",
    "    print(\"Sanity Check failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5377f66",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Cleaning Data\n",
    "- Check showed that trip_id is not unique, so further investigation is needed\n",
    "- Checking on nan/null value \n",
    "- specific cleaning tasks to the geospatial data (polyline):\n",
    "    - Cleaning trips with no POLYLINE or only one coordinate point are assumed invalid and filtered from the dataset\n",
    "    - Assumption that only POLYLINEs with at least 10 coordinate points are interesting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcf96ef-6ae1-42f2-a2cc-b76b464b14be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vc = train_data.trip_id.value_counts().reset_index()\n",
    "# get the trip ids that are duplicated\n",
    "duplicated_trip_ids = vc[vc['count'] > 1]['trip_id'].unique()\n",
    "\n",
    "print(f'{len(duplicated_trip_ids)} trip ids are duplicated')\n",
    "print(f'{(len(duplicated_trip_ids)/train_data.trip_id.nunique()*100)} % out of all unique TRIPs.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde0b7e0-dd01-4b87-9f5d-23132ca257e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vc_test = test_data.trip_id.value_counts().reset_index()\n",
    "# get the trip ids that are duplicated\n",
    "vc_test[vc_test['count'] > 1]['trip_id'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0bc54e",
   "metadata": {},
   "source": [
    "**Findings**:\n",
    "- 159 cases\n",
    "- Missing Data column is set to False for all cases\n",
    "- 80 TRIP_IDs are duplicated\n",
    "- Affected data is insignifcant (less than 1% of all  TRIPs)\n",
    "\n",
    "**Assumptions**:\n",
    "- Potential reasons could be cancellation by dispatcher after a person called for some reasons, failed flight attempts, broken flight taxi etc.\n",
    "- The trips per ID with the longest POLYLINE are kept as these are assumed to be valid trips \n",
    "- Further investigation will should be done and analyzed together with sensor/technical data from flight taxi. Also the reason could be that a flight is interrupted and re-started again, that could be analyzed by plotting the POLYLINE and compare the start and end point of the duplicated TRIPs. Will be part of further optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6ed32b",
   "metadata": {},
   "source": [
    "#### NAN/Null Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ba67ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5088d90",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98693a1b",
   "metadata": {},
   "source": [
    "ORIGIN_CALL and ORIGIN_STAND have null values which is to be expected as they are determined dependent on the call type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69791552",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Data Cleaning POLYLINE\n",
    "To do cleaning regarding the POLYLINE, a few more attributes are calculated:\n",
    "- **n_coordinate_points** - number of total points\n",
    "- **total_flight_time_seconds, total_flight_time_minutes** - flight time total\n",
    "- **start_point** - Starting point for each trip\n",
    "- **dest_point** - Last point for each trip \n",
    "- **total_distance** - total distance of trip in km with haversine formulam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0321d4-41de-4445-8f73-d44b8ba1df94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = calculate_polyline_features(train_data)\n",
    "test_data = calculate_polyline_features(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb45d0c4-06f9-484d-95d1-20e0f829aae0",
   "metadata": {},
   "source": [
    "Based on assumption, keeping only polylines with at least 10 coordinate points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb1209d-11b5-4015-9b6c-dfad8be939c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = filter_invalid_trips(train_data, n_points=10)\n",
    "test_data = filter_invalid_trips(test_data, n_points=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ef2b99-1daa-40de-a7f3-a8d3698a7da3",
   "metadata": {},
   "source": [
    "Calculating the total distance of the trip in km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e3e66b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#TODO \n",
    "train_data = calculate_total_distance(train_data)\n",
    "test_data = calculate_total_distance(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1d516f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data['sequence'] = train_data.polyline.apply(lambda row: np.hstack(row))\n",
    "test_data['sequence'] = test_data.polyline.apply(lambda row: np.hstack(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34594ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = train_data.drop(['polyline'], axis=1)\n",
    "test_data = test_data.drop(['polyline'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b1825f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Missing data columm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35352209",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f'Train Data: {train_data.missing_data.value_counts()} Trips with missing_data == True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7adb70-ce4b-4e54-8c49-40ba026f62e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f'Test Data: {test_data.missing_data.value_counts()} Trips with missing_data == True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779cb316",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data[train_data.missing_data == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4983008b",
   "metadata": {},
   "source": [
    "- Amount of data with missing values insignificant compared to total amount of data\n",
    "- Majority of trips is WEATHER == Rainy, however total amount of trips is not significant enought to draw a conclusion/make an assumption\n",
    "- Number of points/length of polyline is in general unequal so there is no indication in that sense how much data is missing, also no information if data is missing at the start/middle or end of POLYLINE \n",
    "\n",
    "Based on these Findings, I would simply drop these values, mainly as their effect is expected to be very little. If the number of data samples would be higher, I would try to impute the missing coordinates in this case with the Nearest Neighbour. However the problem of knowing if the cooordinates are missing in start/middle/end would prevail. In case I find very similar trips through additional logic (difference in n_coordinate_points <= 5 and overall_distance between points < threshold) I could minimize this problem. These tasks could be part of further optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ebbd47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = train_data[train_data.missing_data != True]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf675a9",
   "metadata": {},
   "source": [
    "#### OUTLIER\n",
    "To handle the outliers, we look at statistical indicators and plot the boxplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8828bcee",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "sns.boxplot(data=train_data[['n_coordinate_points','total_flight_time_minutes','total_distance_km']])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94ef896",
   "metadata": {},
   "source": [
    "The cotinous attributes show a high number of outliers, with the number of coordinate points the widest spread.\n",
    "To avoid loosing too much data, keeping the 95% quantile of the data regarding the N_COORDINATE_POINTS and TOTAL_DISTANCE seems to be the best choice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edd5d06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = train_data[(train_data.n_coordinate_points <= train_data.n_coordinate_points.quantile(0.90))\n",
    "                 & (train_data.total_distance_km <= train_data.total_distance_km.quantile(0.90))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a648c307",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "sns.boxplot(data=train_data[['n_coordinate_points','total_flight_time_minutes','total_distance_km']])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc39cc8e",
   "metadata": {},
   "source": [
    "We can see some outliers remaining, however the spread is significantly reduced. Outliers in the test data will be kept to avoid too much reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912bb117",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.set()\n",
    "plt.hist(train_data.total_flight_time_minutes,\n",
    "         label=f'Post invalid trips N={train_data.shape[0]}')\n",
    "plt.title('Distribution - total flight time in minutes (95% quantile for visualization reasons)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095ddc23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.set()\n",
    "plt.hist(train_data.total_distance_km,\n",
    "         label=f'Post invalid trips N={train_data.shape[0]}')\n",
    "plt.title('Distribution - Count total distance km')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934840d5",
   "metadata": {},
   "source": [
    "The reduction of the training data does not have a major effect on the data distribution. Optimization could be to compare performance with/without outliers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf36a9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    assert(train_data.shape[1] == test_data.shape[1])\n",
    "    print(\"Column shape train vs test passed\")\n",
    "    assert((train_data.columns == test_data.columns).all())\n",
    "    print(\"Column naming train vs test passed\")\n",
    "    assert(train_data.trip_id.nunique() == train_data.shape[0])\n",
    "    print(\"Check for unique trips passed - train data\")\n",
    "    assert(test_data.trip_id.nunique() == test_data.shape[0])\n",
    "    print(\"Check for unique trips passed - test data\")\n",
    "    print('All checks passed!')\n",
    "except:\n",
    "    print(\"Sanity Check failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384185cd",
   "metadata": {},
   "source": [
    "#### 0.5.5 CALL_TYPE LOGIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b74a333",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_call_type(data):\n",
    "    data_A = data[(data.call_type == 'A') & (data.origin_call == np.NaN)]\n",
    "    data_B = data[(data.call_type == 'B') & (data.origin_stand == np.NaN)]\n",
    "    data_C = data[(data.call_type == 'C') & (data.origin_stand != np.NaN)].origin_stand.nunique()\n",
    "    return data_A, data_B, data_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2c6a94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "check_call_type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca47ab5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "check_call_type(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c79ef3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data.drop(['missing_data','total_flight_time_seconds'], axis=1, inplace=True)\n",
    "test_data.drop(['missing_data','total_flight_time_seconds'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f1d7f9-2e22-4855-a0c9-b13264837630",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data.timestamp.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d298d356",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aw.s3.to_parquet(df=train_data, path='s3://think-tank-casestudy/preprocessed_data/train_data_preprocess.parquet', dataset=True, partition_cols=['taxi_id'])\n",
    "aw.s3.to_parquet(df=test_data, path='s3://think-tank-casestudy/preprocessed_data/test_data_preprocess.parquet', dataset=True, partition_cols=['taxi_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4f564e-e0b6-4834-bbdb-909c41599b5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data.trip_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f6dd1c-c6f9-466d-ae7c-af404a334be9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thinktank-casestudy-RPYJc1f2-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
